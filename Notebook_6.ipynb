{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90f07af-e577-4c8b-89ff-67516f2ec533",
   "metadata": {},
   "source": [
    "Load and query Yellow Taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6297fc9-8f4e-4ec0-a065-a77774ed3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d844bb7-86c8-424d-9251-8eff6f4b84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/20 09:16:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "             .master(\"local[1]\")\\\n",
    "             .appName(\"spark-app-version-x\")\\\n",
    "             .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a54fc40d-f26a-413d-b81b-cdf08380ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read taxi data\n",
    "local_files = '/home/sasa/Downloads/Code/notebooks/datasets/parquet'\n",
    "df = spark.read.parquet(local_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e2974b8-fc55-40b7-81bd-493929d1c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|VendorID|total_amount|PULocationID|\n",
      "+--------+------------+------------+\n",
      "|       2|        11.1|         238|\n",
      "|       2|       76.49|         138|\n",
      "|       1|       28.05|         140|\n",
      "|       1|        24.7|         140|\n",
      "|       2|       14.64|          79|\n",
      "+--------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query sample:\n",
    "df.select('VendorID','total_amount', 'PULocationID').show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5c6b42-11fd-4073-9e7d-ea1bd23f1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sample, using Spark SQL\n",
    "df.createOrReplaceTempView('tbl_raw_yellow_taxis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "996d600f-404d-44aa-bd77-bfb9f9c4c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------------+\n",
      "|min(tpep_pickup_datetime)|max(tpep_dropoff_datetime)|\n",
      "+-------------------------+--------------------------+\n",
      "|      2001-01-01 00:06:49|       2023-05-03 23:19:31|\n",
      "+-------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Statement\n",
    "# PULocationID = 188, 379 rows out of 3,066,766\n",
    "spark.sql('''\n",
    "          select min(tpep_pickup_datetime), max(tpep_dropoff_datetime)\n",
    "          from tbl_raw_yellow_taxis\n",
    "          ''').show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b42a5eb-5b9a-4038-9c03-85e3db1eefed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------+\n",
      "|extract(year FROM tpep_pickup_datetime)|count(1)|\n",
      "+---------------------------------------+--------+\n",
      "|                                   2023| 9605947|\n",
      "+---------------------------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# SQL Statement\n",
    "spark.sql('''\n",
    "          select extract(year from tpep_pickup_datetime), count(1)\n",
    "          from tbl_raw_yellow_taxis\n",
    "          group by extract(year from tpep_pickup_datetime)\n",
    "          having count(1) > 100\n",
    "          ''').show(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f1878f-e9fd-4e35-ba53-21b233875390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Statement example, using a subquery to clean the data\n",
    "# Use case example: imagine our business users asked to us delete all data if dataset's year has < 100 rows.\n",
    "df_clean_s1 = spark.sql('''\n",
    "          select *\n",
    "          from tbl_raw_yellow_taxis\n",
    "          where extract(year from tpep_pickup_datetime) in\n",
    "                        (select extract(year from tpep_pickup_datetime)\n",
    "                        from tbl_raw_yellow_taxis\n",
    "                        group by extract(year from tpep_pickup_datetime)\n",
    "                        having count(1) > 100\n",
    "                        )\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "117d1f1b-b428-4142-818b-aac912f2a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register new Temp View, using the cleansed new DataFrame \n",
    "df_clean_s1.createOrReplaceTempView('tbl_raw_yellow_taxis_clean_s1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9017b485-8ecc-4824-b7d3-b8403af4ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------------+\n",
      "|min(tpep_pickup_datetime)|max(tpep_dropoff_datetime)|\n",
      "+-------------------------+--------------------------+\n",
      "|      2023-01-31 23:49:00|       2023-05-03 23:19:31|\n",
      "+-------------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# SQL Statement\n",
    "spark.sql('''\n",
    "          select min(tpep_pickup_datetime), max(tpep_dropoff_datetime)\n",
    "          from tbl_raw_yellow_taxis_clean_s1\n",
    "          ''').show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b514ea89-48a9-47eb-b477-3d4214869ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new partition key\n",
    "df_sink = df_clean_s1.withColumn(\"p_date\",to_date(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fcf9c11-9574-4081-8214-f6ba9c676bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to local storage, if not done already:\n",
    "df_sink.write.partitionBy(\"p_date\").mode(\"overwrite\").parquet(\"/home/sasa/Downloads/Code/notebooks/datasets/yellow_taxis_daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb59ab9b-6e51-4363-a5f2-5136997bf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5884f42-e6f3-42d8-873c-1df1435d2fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
